{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "F1Score.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L4V5PiEafzmY"
      ],
      "authorship_tag": "ABX9TyO9noDfbJnEFQOrAdLWRmUC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ40HMOq4N1u"
      },
      "source": [
        "# Creating Confusion Matrix DataFrame\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcuWmKPz8oKP"
      },
      "source": [
        "Import pandas and numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIA4syoj7asz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oilseS6R8w72"
      },
      "source": [
        "Then we make a pandas dataframe (table) that contain the predicted class and the actual class.\n",
        "\n",
        "We gonna build it like this:\n",
        "*   The column header is the predicted class\n",
        "*   The row index is the actual class\n",
        "\n",
        "```\n",
        "    Predict| class1 | class2 | class3 |\n",
        "    Actual |--------|--------|--------|\n",
        "    -------|--------|--------|--------|\n",
        "    class1 |  ....  |  ....  |  ....  |\n",
        "    class2 |  ....  |  ....  |  ....  |\n",
        "    class3 |  ....  |  ....  |  ....  |\n",
        "```\n",
        "\n",
        "\n",
        "Ok, Step 1, we need all class name for our table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQaTYzJu8v8h"
      },
      "source": [
        "class_name = ['Apple', 'Banana', 'Cherry']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGO2mgCSAf25"
      },
      "source": [
        "Let's make our dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkQwGTEjwy8Z"
      },
      "source": [
        "row_len = len(class_name)\n",
        "col_len = len(class_name)\n",
        "\n",
        "init_val = np.zeros((row_len, col_len), dtype=np.uint)\n",
        "\n",
        "conf_matrix = pd.DataFrame(init_val, index=class_name, columns=class_name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzFySdBpzPJF"
      },
      "source": [
        "* We create confusion table with ``` pandas.Dataframe() ```. \n",
        "\n",
        "* We filled it by zero as our initial value, so we call ```numpy.zeros()``` with shape (row, col).\n",
        "\n",
        "* Row length and column length equal to our number of class, therefore we initiate those variable with ```len(class_name)```.\n",
        "\n",
        "* ```dtype=np.uint``` used to define our data type, numpy unsign integer, because it won't be possible to have negative value.\n",
        "\n",
        "* Finally, creating the DataFrame with index name (row name) and column name same as class name.\n",
        "\n",
        "Let's print our DataFrame. Run the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyl-yLTx3o-",
        "outputId": "e5129fc7-e997-4a26-d98c-4d25c70a418a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "conf_matrix"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Apple</th>\n",
              "      <th>Banana</th>\n",
              "      <th>Cherry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Apple</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Banana</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cherry</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Apple  Banana  Cherry\n",
              "Apple       0       0       0\n",
              "Banana      0       0       0\n",
              "Cherry      0       0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9rDu4WF4VLO"
      },
      "source": [
        "**PURRFECTT!!!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-YwSbYo30nG"
      },
      "source": [
        "# Filling The Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHqs5oUT38w0"
      },
      "source": [
        "Now, how we use it?\n",
        "\n",
        "We need to create dummy data as an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FisnX3p-4_Hx"
      },
      "source": [
        "actual_class = ['Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Banana', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry', 'Cherry']\n",
        "predicted_class = ['Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Banana', 'Cherry', 'Cherry', 'Cherry', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Banana', 'Banana', 'Cherry', 'Cherry', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Banana', 'Banana', 'Banana', 'Cherry']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXfM0GCr6KhG"
      },
      "source": [
        "And to fill it to DataFrame, we could iterate the predicted data as follow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlcxSdFx6Svt"
      },
      "source": [
        "for i in range(len(actual_class)):\n",
        "  conf_matrix[actual_class[i]][predicted_class[i]] += 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzxaAtmN8W4b"
      },
      "source": [
        "Let's check it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IAnEyF98bYD",
        "outputId": "3af12ef4-ad1e-44fb-d0f5-0a69c008a928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "conf_matrix"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Apple</th>\n",
              "      <th>Banana</th>\n",
              "      <th>Cherry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Apple</th>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Banana</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cherry</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Apple  Banana  Cherry\n",
              "Apple       7       8       9\n",
              "Banana      1       2       3\n",
              "Cherry      3       2       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry1p4i1VgIoK"
      },
      "source": [
        "# Ok, now.... What's confusion matrix used for? \n",
        "\n",
        "Actually we could use it to calculate the performance measure of our model, for example F1-score. But before do that, I'mma explain you something. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIe-oh8Mfd2T"
      },
      "source": [
        "# Precission\n",
        "\n",
        "Based on Wikipedia, precision is:\n",
        "> *... the number of correctly identified positive results divided by the number of all positive results, including those not identified correctly.*\n",
        "\n",
        "From that explanation, we could write the formula of precission like this:\n",
        "\n",
        "```\n",
        "                   TP \n",
        "   Precission = ---------\n",
        "                (TP + FP)      \n",
        "\n",
        "Where:\n",
        "   TP = True Positive \n",
        "   FP = False Positive          \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x9ReU6PiKOS"
      },
      "source": [
        "# Code\n",
        "\n",
        "Here's the code to calculate Precission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SgLYuhxiG1m"
      },
      "source": [
        "def precission(label, confusion_matrix):\n",
        "  true_positive = confusion_matrix.loc[label, label]\n",
        "  return true_positive/np.sum(confusion_matrix.loc[label, :])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4V5PiEafzmY"
      },
      "source": [
        "# Recall\n",
        "\n",
        "Based on Wikipedia:\n",
        "> *Recall is the number of correctly identified positive results divided by the number of all samples that should have been identified as positive.*\n",
        "\n",
        "And the formula is:\n",
        "\n",
        "```\n",
        "               TP\n",
        "   Recall = ---------\n",
        "            (TP + FN)      \n",
        "\n",
        "Where:\n",
        "   TP = True Positive \n",
        "   FP = False Positive\n",
        "   FN = False Negative\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGXsxxQFjF7I"
      },
      "source": [
        "***Note:***\n",
        "\n",
        "True Positive  : The predicted class (+) the actual class is (+)\n",
        "\n",
        "True Negative  : The predicted class (-) the actual class is (-)\n",
        "\n",
        "False Positive : The predicted class (+) the actual class is (-)\n",
        "\n",
        "False Negative : The predicted class (-) the actual class is (+)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1mTvdCYjh2y"
      },
      "source": [
        "# Code\n",
        "\n",
        "Here's the code to calculate Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mGCtdChjh20"
      },
      "source": [
        "def recall(label, confusion_matrix):\n",
        "  true_positive = confusion_matrix.loc[label, label]\n",
        "  return true_positive / np.sum(confusion_matrix.loc[:, label])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aieorwrJfYni"
      },
      "source": [
        "# What Is F1-Score? \n",
        "\n",
        "Based on Wikipedia: \n",
        "> *F1-Score (F-Score or F-Measure) is a measure of a test's accuracy. F1-Score is the harmonic mean of the precision and recall.*\n",
        "\n",
        "The formula to calculate F1-Score is:\n",
        "\n",
        "```\n",
        "                  (precission * recall) \n",
        "   F1_score = 2 * ---------------------\n",
        "                  (precission + recall)       \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggyZlH5fmxqH"
      },
      "source": [
        "# Code\n",
        "\n",
        "Here's the code to calculate the F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bjrdd5hne-l"
      },
      "source": [
        "def f1_score(label, precission, recall):\n",
        "  return 2 * (precission * recall) / (precission + recall)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5OI9Ze7qY4H"
      },
      "source": [
        "# Calculating F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgo7dg6aqv0O",
        "outputId": "b028ac58-8cfd-4668-a60f-8184a48e516d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "result_df = pd.DataFrame(data=None, index=class_name, columns=['Precission', 'Recall', 'F1_score'], dtype=np.float)\n",
        "\n",
        "for fruit in result_df.index:\n",
        "  precission_val = precission(fruit, conf_matrix)\n",
        "  recall_val = recall(fruit, conf_matrix)\n",
        "  f1_score_val = f1_score(fruit, precission_val, recall_val)\n",
        "\n",
        "  result_df.loc[fruit]['Precission'] = precission_val\n",
        "  result_df.loc[fruit]['Recall'] = recall_val\n",
        "  result_df.loc[fruit]['F1_score'] = f1_score_val\n",
        "\n",
        "print(result_df.round(2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precission</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Apple</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Banana</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cherry</th>\n",
              "      <td>0.17</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Precission  Recall  F1_score\n",
              "Apple         0.29    0.64      0.40\n",
              "Banana        0.33    0.17      0.22\n",
              "Cherry        0.17    0.08      0.11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQoy6kHyoGow"
      },
      "source": [
        "# Which One to Use?\n",
        "\n",
        "\n",
        "\n",
        "*   F1-Score is best to use if we have an uneven class distribution. \n",
        "*   Precission best to use when we want to be more confident for the true positive, e.g spam emails. You'd rather have some spam emails in inbox than regular email in spam box. So, the email company want to be extra sure that an email is spam before they put it on the spam box and never get to see it. \n",
        "*   Recall best to use when the occurrence of false negatives is unaccepted/intolerable, e.g when predicting about whether a person have any disease or not, you'd rather choose a person labeled as false positive (identified have a disease but actually not) rather than false negative (identified not have a disease but actually have)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp_hykE1597F"
      },
      "source": [
        "Reference:\n",
        "\n",
        "1. Wikipedia\n",
        "\n",
        "2. towardsdatascience.com"
      ]
    }
  ]
}